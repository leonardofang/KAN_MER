# Code source for submission to ICASSP 2025
## KAN-based multimodal emotion recognition

# Environment:
## Python 3.8.18; Tensorflow 2.12.0


# Files:
## 1) fastkan.py shows the oroginal KAN-based model while fastkan_attention.py describes the KAN-based by integrating attention mechanism
## 2) eval_kan.py indicates the implemntation code for experiments.

# Datasets in this study: 
# 1) Emo-MG <a href="https://doi.org/10.1080/10447318.2023.2228983" target="_blank" rel="noopener noreferrer">
# 2) IEMOCAP <a href="https://sail.usc.edu/iemocap/" target="_blank" rel="noopener noreferrer">
# 3) EMOTIC <a href="https://github.com/rkosti/emotic" target="_blank" rel="noopener noreferrer">
